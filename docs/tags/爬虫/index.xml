<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>爬虫 on Team317</title>
    <link>https://team317.gitee.io/tags/%E7%88%AC%E8%99%AB/</link>
    <description>Recent content in 爬虫 on Team317</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 May 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://team317.gitee.io/tags/%E7%88%AC%E8%99%AB/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>知乎热榜爬取</title>
      <link>https://team317.gitee.io/python%E7%AC%94%E8%AE%B0/%E7%9F%A5%E4%B9%8E%E7%83%AD%E6%A6%9C%E7%88%AC%E5%8F%96/</link>
      <pubDate>Fri, 30 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://team317.gitee.io/python%E7%AC%94%E8%AE%B0/%E7%9F%A5%E4%B9%8E%E7%83%AD%E6%A6%9C%E7%88%AC%E5%8F%96/</guid>
      <description>&lt;p&gt;&lt;strong&gt;任务概述&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这次的任务是定时的爬取知乎热榜前十的标题，如果当前爬取的热榜较上一次有所变动，则将新增的标题打印出来。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>爬虫：设置手机代理</title>
      <link>https://team317.gitee.io/python%E7%AC%94%E8%AE%B0/%E7%88%AC%E8%99%AB%E8%AE%BE%E7%BD%AE%E6%89%8B%E6%9C%BA%E4%BB%A3%E7%90%86/</link>
      <pubDate>Mon, 03 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://team317.gitee.io/python%E7%AC%94%E8%AE%B0/%E7%88%AC%E8%99%AB%E8%AE%BE%E7%BD%AE%E6%89%8B%E6%9C%BA%E4%BB%A3%E7%90%86/</guid>
      <description>&lt;h3 id=&#34;mitmproxy的安装&#34;&gt;mitmproxy的安装&lt;/h3&gt;
&lt;p&gt;如果安装了anaconda，则在终端执行&lt;code&gt;pip install mitmproxy&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;安装后在目录下会增加三个可执行文件&lt;code&gt;mitmproxy.exe&lt;/code&gt;、&lt;code&gt;mitmdump.exe&lt;/code&gt;、&lt;code&gt;mitmweb.exe&lt;/code&gt;，为了能够在终端直接使用mitmdump命令，需将其文件路径添加到环境变量中，我的路径是&lt;code&gt;D:\InstallationLocation\Anaconda\envs\WebCrawler\Scripts&lt;/code&gt;，其中WebCrawler是我的虚拟环境。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>用selenium抓取淘宝页面商品信息</title>
      <link>https://team317.gitee.io/python%E7%AC%94%E8%AE%B0/%E7%94%A8selenium%E6%8A%93%E5%8F%96%E6%B7%98%E5%AE%9D%E9%A1%B5%E9%9D%A2%E5%95%86%E5%93%81%E4%BF%A1%E6%81%AF/</link>
      <pubDate>Mon, 03 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://team317.gitee.io/python%E7%AC%94%E8%AE%B0/%E7%94%A8selenium%E6%8A%93%E5%8F%96%E6%B7%98%E5%AE%9D%E9%A1%B5%E9%9D%A2%E5%95%86%E5%93%81%E4%BF%A1%E6%81%AF/</guid>
      <description>&lt;p&gt;&lt;strong&gt;问题概述&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用selenium登录淘宝并抓取关键字&amp;quot;iPad&amp;quot;对应页面的商品信息。&lt;/p&gt;
&lt;p&gt;页面的抓取使用requests应该也能做到，这次的话使用selenium获取每一页的信息，然后用pyquery对页面信息进行处理。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
